name: "Physics Paper Analysis Feedback Model"
version: 26.02.12.1
author: "Exergy âˆž LLC"

entities:
  - name: session_feedback
    brief: "Session feedback for physics paper entity creation and analysis"
    description: |
      Top-level feedback entity for tracking AI-assisted physics paper analysis sessions.
      
      **CRITICAL INSTRUCTION FOR LARGE LLMs**: The feedback you provide is for HUMAN ARCHITECTS who
      are designing and improving the system for physics paper analysis. Your feedback should help
      architects understand:
      
      1. **What patterns cause failures**: Document specific patterns where mistakes occur when
         extracting physics facts from papers. Help architects understand what causes these failures,
         especially regarding correctness, completeness, minimal representation, and consistency.
      
      2. **What model guidance is unclear**: Identify places where entity descriptions, field
         descriptions, or model instructions are ambiguous or require too much interpretation when
         analyzing physics papers. Explicit, prescriptive guidance is needed on what constitutes a
         minimal, correct, and complete representation of physics facts.
      
      3. **What structural changes would help**: Suggest concrete improvements to the data model
         structure, entity definitions, or field descriptions that would make it easier to extract
         and represent physics facts correctly and completely. Think about what information is missing
         or hard to find when analyzing papers.
      
      4. **What workflow patterns work/fail**: Document which workflow patterns work successfully
         vs. which require too much reasoning when processing physics papers. Help architects design
         workflows that ensure correctness, completeness, minimal representation, and consistency.
      
      5. **What validation errors reveal**: When validation fails, explain what the error message
         tells you and whether it's clear enough to understand and fix, especially in the context
         of physics fact extraction.
      
      **KEY SUCCESS CRITERIA FOR PHYSICS PAPER ANALYSIS**:
      - **Correctness**: Physics facts, equations, dates, relationships, and scientific statements
        must be accurate and verifiable. No incorrect physics content should be extracted.
      - **Completeness**: All key facts from papers must be captured - theories, assumptions, postulates,
        claims, predictions, people, papers, and their relationships. Nothing essential should be missed.
      - **Minimal Representation**: Avoid redundancy. Each fact should be represented once in the most
        appropriate entity. Statements should be concise and essential, avoiding unnecessary verbosity.
      - **Consistency**: Data must be consistent across entities - years match, relationships are
        bidirectional where needed, entity IDs are used consistently, and no contradictory information.
      
      Your goal is to provide actionable insights that help human architects improve the system
      through better model design, clearer guidance, and more effective workflows that ensure
      high-quality physics fact extraction.
    primary_key: [session_id]
    fields:
      - name: session_id
        type: string
        primaryKey: true
        required: true
        description: |
          Unique session identifier. Automatically generated by the MCP server when get_model
          is called. Used to track all queries and entity operations within a session.
      - name: session_assessment
        type: array
        item_type:
          entity: session_assessment
        required: true
        description: |
          AI's comprehensive assessment of the session, including efficiency metrics, validation
          tracking, and quality evaluation. Must be provided for every session to enable
          continuous improvement.
      - name: user_feedback
        type: array
        item_type:
          entity: user_feedback
        required: false
        description: |
          Optional user-provided feedback about the session, including ratings and comments.
      - name: ai_feedback
        type: array
        item_type:
          entity: ai_feedback
        required: true
        description: |
          AI-generated feedback about the session, including processing summary, tools used,
          challenges encountered, and insights for improvement.

  - name: session_assessment
    brief: "AI assessment of session quality and efficiency for physics paper analysis"
    description: |
      Comprehensive assessment of the session's quality, efficiency, and areas for improvement
      in physics paper analysis.
      
      **INSTRUCTION FOR LARGE LLMs**: When assessing the session, think from the perspective of
      helping human architects understand how to improve the system for physics paper analysis.
      Your assessment should:
      
      1. **Identify systemic issues**: Don't just document what happened - identify what in the
         model design, guidance, or workflow made extracting physics facts difficult. What would
         need to change in the model to ensure correctness, completeness, minimal representation,
         and consistency?
      
      2. **Evaluate model clarity**: Assess whether entity descriptions, field descriptions, and
         required_fields arrays are clear enough when processing physics papers. Are there ambiguities
         that require interpretation? What guidance is missing for ensuring correct physics fact
         extraction?
      
      3. **Document reasoning requirements**: Identify places where the workflow requires reasoning
         or interpretation when analyzing physics content. What would make it more mechanical while
         ensuring correctness and completeness?
      
      4. **Suggest model improvements**: When documenting issues, suggest specific changes to the
         data model that would help. For example: "The entity description doesn't explicitly state
         that all required_fields must be provided. Adding a clear statement would help avoid
         incomplete physics fact extraction."
      
      5. **Assess error message quality**: When validation fails, evaluate whether the error message
         is clear enough to understand and fix, especially in the context of physics fact extraction.
         What information is missing?
      
      6. **Evaluate physics-specific quality**: Assess correctness (accurate physics facts),
         completeness (all key facts captured), minimal representation (no redundancy), and
         consistency (consistent relationships and data across entities).
      
      Frame your assessment to help architects understand what improvements are needed to ensure
      correct, complete, minimal, and consistent physics fact extraction.
    parents:
      - child_fk: session_id
        parent_array: session_assessment
    primary_key: [session_id]
    fields:
      - name: session_id
        type: string
        primaryKey: true
        required: true
        foreignKey:
          entity: session_feedback
          field: session_id
        description: |
          Reference to the parent session feedback record.
      - name: overall_success
        type: boolean
        required: true
        description: |
          Whether the session completed successfully. Set to false if critical errors occurred
          that prevented completion or if significant data quality issues were identified.
      - name: efficiency_score
        type: number
        min: 0
        max: 1
        required: true
        description: |
          Efficiency score (0.0-1.0) evaluating how efficiently the session executed.
          
          **INSTRUCTION FOR LARGE LLMs**: When scoring efficiency, think about what this reveals
          to human architects about the system's design. Document:
          
          1. **What inefficiencies occurred**: Be specific about what happened (e.g., "Called
             get_model() 5 times" not "Inefficient queries")
          
          2. **Why they occurred**: Explain what in the model design or workflow made these
             inefficiencies likely. For example: "Multiple get_model() calls occurred because
             the model doesn't clearly indicate that one call at the start is sufficient, and
             the result can be cached."
          
          3. **What would prevent them**: Suggest model improvements. For example: "Adding explicit
             guidance in entity descriptions: 'Call get_model() once at session start and reuse
             the result' would help avoid redundant calls."
          
          4. **Score calculation**: Document how you calculated the score, focusing on what it
             reveals about system design. For example: "Efficiency score: 0.6. Major issues:
             (1) 3 redundant get_model() calls - suggests model guidance should emphasize caching,
             (2) Missing required_fields check - suggests required_fields array should be more
             prominently displayed or guidance should be more explicit for physics entity extraction."
      - name: data_quality_score
        type: number
        min: 0
        max: 1
        required: true
        description: |
          Data quality score (0.0-1.0) evaluating the quality of created entities.
          
          **INSTRUCTION FOR LARGE LLMs**: When scoring data quality, focus on what this reveals
          to human architects about model design issues. Document:
          
          1. **What validation failures occurred**: List specific failures with entity types and
             missing/incorrect fields.
          
          2. **Why they occurred**: Explain what in the model design made these failures likely.
             For example: "Validation failure for 'theory' entity missing 'year' occurred because:
             (1) The required_fields array exists but isn't prominently displayed in get_model()
             response at default depth, (2) The entity description doesn't explicitly list required
             fields, (3) Field-level 'required: true' flags aren't visible without deeper model
             queries. This is critical for physics papers where dates are essential for correctness."
          
          3. **What model changes would prevent them**: Suggest specific improvements. For example:
             "Adding required_fields to the default get_model() response (depth=1) would help.
             Alternatively, adding explicit guidance in entity description: 'Required fields:
             theory_id, name, year' would make it immediately clear. For physics papers, ensuring
             year is captured is essential for correctness and consistency."
          
          4. **Score calculation with insights**: Document the score calculation and what it
             reveals. For example: "Data quality score: 0.7. Two validation failures occurred,
             both due to missing required fields (theory.year, paper.year) that weren't obvious
             from the model response. This suggests the model should make required_fields more
             discoverable, especially for physics entities where dates are critical for correctness."
      - name: validation_failures
        type: array
        item_type:
          entity: validation_failure
        required: false
        description: |
          List of validation failures encountered during the session. Each failure should be
          documented with entity type, error message, and resolution. Empty if no validation
          failures occurred.
      - name: workflow_issues
        type: array
        item_type:
          primitive: string
        required: false
        description: |
          List of workflow issues identified during the session.
          
          **INSTRUCTION FOR LARGE LLMs**: Document workflow issues to help human architects
          understand what makes the system difficult. Use this format:
          
          "Issue: [What happened] | Root Cause: [What in the model/workflow design caused this] |
          Impact: [Why this is problematic] | Suggested Model Change: [Specific change to model/guidance
          that would help]"
          
          Examples:
          - "Issue: Validation failure for 'theory' entity missing 'year' | Root Cause: The
            required_fields array is only visible at depth=2 in get_model(), but depth=1 is often
            used. The entity description doesn't explicitly list required fields. For physics papers,
            year is critical for correctness and consistency. | Impact: Required fields not visible
            immediately, leading to incomplete physics fact extraction. | Suggested Model Change:
            Add required_fields to depth=1 response, or add explicit 'Required fields: [list]' to
            entity description."
          
          - "Issue: Duplicate 'person' entities created for same physicist | Root Cause: No explicit
            guidance on checking existing entities before creation. | Impact: Creates data inconsistency
            and violates minimal representation principle. | Suggested Model Change: Add guidance in
            model description: 'Check for existing entities using get_entity() before creating to
            ensure consistency and minimal representation.'"
          
          - "Issue: Called get_model() 5 times unnecessarily | Root Cause: No explicit guidance
            in model that get_model() result can be cached and reused. | Impact: Multiple calls waste
            resources and increase latency when processing physics papers. | Suggested Model Change:
            Add guidance in model description: 'Call get_model() once at session start and cache the
            result for reuse.'"
          
          Focus on helping architects understand what model design changes would prevent these issues.
      - name: workflow_strengths
        type: array
        item_type:
          primitive: string
        required: false
        description: |
          List of workflow strengths observed during the session.
          
          **INSTRUCTION FOR LARGE LLMs**: Document workflow strengths to help human architects
          understand what model design elements enable success. Use this format:
          
          "Strength: [What was done well] | What Enabled This: [What in the model design made
          this possible] | How to Replicate: [What model changes would make this pattern more
          accessible]"
          
          Examples:
          - "Strength: All physics entities created successfully on first attempt with correct
            required fields | What Enabled This: The required_fields array was visible in get_model()
            response at depth=1, and entity description explicitly stated 'Required fields must
            be provided'. This ensured correctness and completeness. | How to Replicate: Ensure
            required_fields are always visible at default depth, and add explicit 'Required fields:
            [list]' to all entity descriptions, especially for physics entities where dates and IDs
            are critical."
          
          - "Strength: Efficient batch operations used for extracting multiple theories from paper |
            What Enabled This: The model clearly indicated that multiple entities of the same type
            can be created in parallel, and the create_entity tool documentation showed batch examples.
            This maintained minimal representation by avoiding redundant operations. | How to Replicate:
            Add explicit guidance in model: 'When extracting multiple physics entities from a paper,
            collect all data first, then create in batch to improve efficiency and ensure consistency.'"
          
          - "Strength: Consistent relationships maintained (theory.papers and paper references match) |
            What Enabled This: The model clearly showed bidirectional relationship patterns and
            explicit guidance on maintaining consistency. | How to Replicate: Add explicit guidance:
            'When linking theories to papers, ensure bidirectional consistency: if theory.papers
            includes paper_id, verify the relationship is consistent across entities.'"
          
          Focus on identifying what in the model design made success possible, so architects
          can replicate these patterns.
      - name: recommendations
        type: array
        item_type:
          entity: recommendation
        required: false
        description: |
          Actionable recommendations for improving future sessions. Should include specific,
          implementable suggestions based on issues identified in this session.
      - name: efficiency_metrics
        type: array
        item_type:
          entity: efficiency_metrics
        required: true
        description: |
          Detailed efficiency metrics for the session, including query counts, timing,
          and performance indicators.

  - name: validation_failure
    brief: "Documentation of a validation failure"
    description: |
      Detailed documentation of a validation failure that occurred during entity creation.
      Captures the entity type, error message, missing fields, and how it was resolved.
      This enables pattern detection and helps prevent similar failures in future sessions.
    parents:
      - child_fk: session_id
        parent_array: validation_failures
    primary_key: [session_id, failure_sequence]
    fields:
      - name: session_id
        type: string
        primaryKey: true
        required: true
        foreignKey:
          entity: session_assessment
          field: session_id
        description: |
          Reference to the parent session assessment record.
      - name: failure_sequence
        type: integer
        min: 1
        primaryKey: true
        required: true
        description: |
          Sequence number of this validation failure within the session (1 = first failure,
          2 = second failure, etc.). Used to track multiple failures and their order.
      - name: error_message
        type: string
        required: true
        description: |
          Full error message from the validation failure. Should include field path and
          specific validation error details.
      - name: missing_required_fields
        type: array
        item_type:
          primitive: string
        required: false
        description: |
          List of required fields that were missing from the entity data. Empty if the
          failure was not due to missing required fields.
      - name: validation_failure_details
        type: array
        item_type:
          entity: validation_failure_details
        required: true
        description: |
          Details about the validation failure including entity type, primary key, error
          type, and resolution notes. Each validation_failure should have exactly one
          validation_failure_details record.
      - name: validation_failure_resolution
        type: array
        item_type:
          entity: validation_failure_resolution
        required: true
        description: |
          Resolution information for the validation failure including resolution attempts
          and whether it was resolved. Each validation_failure should have exactly one
          validation_failure_resolution record.

  - name: validation_failure_details
    brief: "Details about a validation failure"
    description: |
      Detailed information about a validation failure including the entity that failed,
      error type, and resolution notes. This information helps identify patterns in
      validation failures and improve error prevention.
    parents:
      - child_fk: session_id
        parent_array: validation_failure_details
    primary_key: [session_id, failure_sequence]
    fields:
      - name: session_id
        type: string
        primaryKey: true
        required: true
        foreignKey:
          entity: validation_failure
          field: session_id
        description: |
          Reference to the parent validation_failure record.
      - name: failure_sequence
        type: integer
        min: 1
        primaryKey: true
        required: true
        foreignKey:
          entity: validation_failure
          field: failure_sequence
        description: |
          Reference to the parent validation_failure record.
      - name: entity_type
        type: string
        required: true
        description: |
          Type of entity that failed validation (e.g., "theory", "paper", "person", "assumption",
          "postulate", "claim", "prediction").
      - name: entity_primary_key
        type: string
        required: false
        description: |
          Primary key value of the entity that failed validation. Helps identify specific
          entity instances that had issues.
      - name: error_type
        type: string
        required: true
        description: |
          Type of validation error (e.g., "ValidationError", "MissingRequiredField",
          "TypeMismatch", "ConstraintViolation").
      - name: resolution_notes
        type: string
        required: false
        description: |
          Notes about how the validation failure was resolved, including what fields
          were added or corrected. Useful for understanding error recovery patterns.

  - name: validation_failure_resolution
    brief: "Resolution information for a validation failure"
    description: |
      Information about how a validation failure was resolved, including the number of
      attempts and whether it was successfully resolved. This helps track error recovery
      patterns and identify failures that are difficult to resolve.
    parents:
      - child_fk: session_id
        parent_array: validation_failure_resolution
    primary_key: [session_id, failure_sequence]
    fields:
      - name: session_id
        type: string
        primaryKey: true
        required: true
        foreignKey:
          entity: validation_failure
          field: session_id
        description: |
          Reference to the parent validation_failure record.
      - name: failure_sequence
        type: integer
        min: 1
        primaryKey: true
        required: true
        foreignKey:
          entity: validation_failure
          field: failure_sequence
        description: |
          Reference to the parent validation_failure record.
      - name: resolution_attempts
        type: integer
        min: 1
        required: true
        description: |
          Number of attempts made to resolve this validation failure. Higher numbers
          indicate more complex resolution or multiple issues that needed fixing.
      - name: resolved
        type: boolean
        required: true
        description: |
          Whether the validation failure was successfully resolved. Set to false if the
          entity creation ultimately failed or was abandoned.

  - name: recommendation
    brief: "Actionable recommendation for improvement"
    description: |
      Specific, actionable recommendation for improving the system for physics paper analysis.
      
      **INSTRUCTION FOR LARGE LLMs**: Write recommendations for HUMAN ARCHITECTS who will modify
      the data model, entity descriptions, or system design. Each recommendation should:
      
      1. **Identify the Problem**: Clearly state what issue occurs and why it's problematic.
      
      2. **Propose Model Changes**: Suggest specific, concrete changes to the data model,
         entity descriptions, field descriptions, or system design that would help. Be specific:
         "Add 'Required fields: [list]' to entity description" not "Make required fields clearer".
      
      3. **Explain the Impact**: Describe how the proposed change would help. What ambiguity would
         it eliminate? How would it improve correctness, completeness, minimal representation, or
         consistency?
      
      4. **Provide Examples**: Show before/after examples of how the model would look with your
         suggested changes.
      
      5. **Prioritize by Impact**: Critical = prevents validation failures, High = significantly
         improves success rate, Medium = improves efficiency, Low = minor optimizations.
      
      Frame recommendations as: "To improve physics paper analysis, architects should [specific
      model change] because [why this helps]."
    parents:
      - child_fk: session_id
        parent_array: recommendations
    primary_key: [session_id, recommendation_sequence]
    fields:
      - name: session_id
        type: string
        primaryKey: true
        required: true
        foreignKey:
          entity: session_assessment
          field: session_id
        description: |
          Reference to the parent session assessment record.
      - name: recommendation_sequence
        type: integer
        min: 1
        primaryKey: true
        required: true
        description: |
          Sequence number of this recommendation within the session (1 = first recommendation,
          2 = second recommendation, etc.). Used to prioritize and track multiple recommendations.
      - name: category
        type: string
        enum: ["validation", "efficiency", "data_quality", "workflow", "error_handling", "model_usage"]
        required: true
        description: |
          Category of the recommendation:
          - "validation": Pre-validation, required field checking
          - "efficiency": Query optimization, batch operations
          - "data_quality": Entity completeness, accuracy
          - "workflow": Process improvements, workflow patterns
          - "error_handling": Error recovery, failure handling
          - "model_usage": Model query patterns, depth selection
      - name: priority
        type: string
        enum: ["critical", "high", "medium", "low"]
        required: true
        description: |
          Priority level of the recommendation:
          - "critical": Must be addressed, causes failures or data quality issues
          - "high": Should be addressed, significantly impacts efficiency or quality
          - "medium": Recommended improvement, moderate impact
          - "low": Nice to have, minor optimization opportunity
      - name: title
        type: string
        required: true
        description: |
          Brief, descriptive title for the recommendation targeting human architects.
          
          **INSTRUCTION FOR LARGE LLMs**: Write titles as specific model change recommendations
          for architects. Use format: "Add [specific change] to [entity/field/model] to [benefit]"
          
          Good examples:
          - "Add required_fields array to depth=1 get_model() response to make required fields
            immediately visible when analyzing physics papers"
          - "Add explicit 'Required fields: [list]' to entity descriptions (especially theory, paper,
            person) to reduce need for multiple model queries and ensure completeness"
          - "Add guidance in model description: 'Call get_model() once and cache result' to prevent
            redundant queries when processing physics papers"
          - "Add consistency checks: 'Verify years match across related entities (theory.year,
            paper.year, person birth/death years)' to ensure correctness"
          
          Bad examples (too abstract):
          - "Improve validation workflow"
          - "Make required fields clearer"
          - "Optimize model queries"
          - "Better physics extraction"
      - name: description
        type: string
        required: true
        description: |
          Detailed description of the recommendation for human architects.
          
          **INSTRUCTION FOR LARGE LLMs**: Write descriptions to help architects understand what
          to change and why. Include:
          
          1. **The Problem**: What issue occurs (1-2 sentences)
          2. **Why It's Problematic**: What makes this problematic for physics paper analysis
          3. **The Proposed Change**: Exact model/design change to make (be specific)
          4. **Expected Impact**: How this change would help improve physics fact extraction
          5. **Example**: Show before/after of the model with the change
          
          Format:
          "Problem: [What issue occurs]. Why it's problematic: [What makes this problematic].
          Proposed change: [Exact model modification]. Expected impact: [How this helps].
          Example: [Before/after showing the change]."
          
          Example:
          "Problem: Required fields (especially year fields) are missed when extracting physics
          facts from papers because required_fields array is only visible at depth=2 in get_model(),
          but depth=1 is often used. Why it's problematic: For physics papers, missing year fields
          causes correctness and consistency issues. Multiple get_model() calls at different depths
          are inefficient. Proposed change: Add required_fields array to depth=1 response in
          get_model() tool, or add explicit 'Required fields: [list]' to entity description.
          Expected impact: Required fields will be visible immediately without additional queries,
          ensuring complete and correct physics fact extraction. Example: Entity description
          currently says 'Represents a physics theory...'. After change: 'Represents a physics
          theory. Required fields: theory_id, name, year. The year field is critical for correctness
          and consistency with related papers and people.'"
      - name: implementation_guidance
        type: string
        required: false
        description: |
          Specific guidance on how architects should implement this recommendation.
          
          **INSTRUCTION FOR LARGE LLMs**: Provide implementation guidance for human architects
          who will modify the data model. Include:
          
          1. **Where to Make the Change**: Exact file location and entity/field to modify
          2. **What to Add/Change**: Specific text or structure to add/modify
          3. **Code/Structure Example**: Show the exact YAML or structure change
          4. **Validation**: How to verify the change works
          5. **Testing**: How to test that the change improves physics paper analysis
          
          Format:
          "Implementation steps:
          1. Location: [File path and entity/field]
          2. Change: [Specific modification]
          3. Example: [Before/after YAML or structure]
          4. Validation: [How to verify]
          5. Testing: [How to test impact on physics paper analysis]"
          
          Example:
          "Implementation steps:
          1. Location: data/physics/model/physics-theory.yaml, entity 'theory', description field
          2. Change: Add explicit required fields list to description, emphasizing importance of
             year for correctness
          3. Example: Before: 'Represents a physics theory...' After: 'Represents a physics theory.
             Required fields: theory_id, name, year. The year field is critical for correctness
             and consistency with related papers and people.'
          4. Validation: Run consolidator to verify YAML is valid
          5. Testing: Test by analyzing physics papers - verify required fields are visible without
             additional get_model() calls and year information is correctly extracted"

  - name: efficiency_metrics
    brief: "Detailed efficiency metrics for the session"
    description: |
      Detailed metrics tracking session efficiency, including query counts, timing,
      entity creation patterns, and performance indicators. Used to identify optimization
      opportunities and track efficiency improvements over time.
    parents:
      - child_fk: session_id
        parent_array: efficiency_metrics
    primary_key: [session_id]
    fields:
      - name: session_id
        type: string
        primaryKey: true
        required: true
        foreignKey:
          entity: session_assessment
          field: session_id
        description: |
          Reference to the parent session assessment record.
      - name: efficiency_timing_metrics
        type: array
        item_type:
          entity: efficiency_timing_metrics
        required: true
        description: |
          Timing-related efficiency metrics including session duration and calculated
          rates. Each efficiency_metrics record should have exactly one
          efficiency_timing_metrics record.
      - name: efficiency_count_metrics
        type: array
        item_type:
          entity: efficiency_count_metrics
        required: true
        description: |
          Count-based efficiency metrics including total queries, entities created,
          validation failures, and model queries. Each efficiency_metrics record should
          have exactly one efficiency_count_metrics record.
      - name: efficiency_optimization_metrics
        type: array
        item_type:
          entity: efficiency_optimization_metrics
        required: true
        description: |
          Optimization-related efficiency metrics including redundant queries, entity
          existence checks, and batch operations. Each efficiency_metrics record should
          have exactly one efficiency_optimization_metrics record.

  - name: efficiency_timing_metrics
    brief: "Timing-related efficiency metrics"
    description: |
      Metrics tracking session timing including duration and calculated rates for queries
      and entity creation. These metrics help identify slow sessions and track performance
      improvements.
    parents:
      - child_fk: session_id
        parent_array: efficiency_timing_metrics
    primary_key: [session_id]
    fields:
      - name: session_id
        type: string
        primaryKey: true
        required: true
        foreignKey:
          entity: efficiency_metrics
          field: session_id
        description: |
          Reference to the parent efficiency_metrics record.
      - name: session_duration_seconds
        type: number
        min: 0
        required: true
        description: |
          Total duration of the session in seconds, from first query to finalize_session.
          Used to calculate queries per second and identify slow sessions.
      - name: queries_per_second
        type: number
        min: 0
        required: false
        description: |
          Calculated queries per second (total_queries / session_duration_seconds).
          Higher values indicate more efficient session execution.
      - name: entities_per_second
        type: number
        min: 0
        required: false
        description: |
          Calculated entities created per second (entities_created / session_duration_seconds).
          Higher values indicate more efficient entity creation.

  - name: efficiency_count_metrics
    brief: "Count-based efficiency metrics"
    description: |
      Metrics tracking counts of queries, entities, and validation failures. These metrics
      help understand session scope and identify areas for optimization.
    parents:
      - child_fk: session_id
        parent_array: efficiency_count_metrics
    primary_key: [session_id]
    fields:
      - name: session_id
        type: string
        primaryKey: true
        required: true
        foreignKey:
          entity: efficiency_metrics
          field: session_id
        description: |
          Reference to the parent efficiency_metrics record.
      - name: total_queries
        type: integer
        min: 0
        required: true
        description: |
          Total number of queries executed during the session. Includes all tool calls
          (get_model, create_entity, get_entity, jmespath_query, etc.).
      - name: entities_created
        type: integer
        min: 0
        required: true
        description: |
          Total number of entities successfully created during the session. Includes
          all entity types (theory, paper, person, assumption, postulate, claim, prediction,
          relationships, etc.).
      - name: validation_failure_count
        type: integer
        min: 0
        required: true
        description: |
          Total number of validation failures encountered during the session. Higher
          values indicate need for better pre-validation.
      - name: model_query_count
        type: integer
        min: 0
        required: true
        description: |
          Number of get_model queries executed. Should typically be 1-2. Higher values
          may indicate suboptimal depth selection or workflow issues.

  - name: efficiency_optimization_metrics
    brief: "Optimization-related efficiency metrics"
    description: |
      Metrics tracking optimization opportunities including redundant queries, entity
      existence checks, and batch operations. These metrics help identify workflow
      improvements and best practices.
    parents:
      - child_fk: session_id
        parent_array: efficiency_optimization_metrics
    primary_key: [session_id]
    fields:
      - name: session_id
        type: string
        primaryKey: true
        required: true
        foreignKey:
          entity: efficiency_metrics
          field: session_id
        description: |
          Reference to the parent efficiency_metrics record.
      - name: redundant_queries
        type: integer
        min: 0
        required: false
        description: |
          Number of redundant queries identified (e.g., multiple get_model calls with
          different depths when one would suffice, checking entities that were just created).
          Lower values indicate better query optimization.
      - name: entity_existence_checks
        type: integer
        min: 0
        required: false
        description: |
          Number of times existing entities were checked before creation (get_entity calls
          to avoid duplicates). Higher values indicate better data quality practices.
      - name: batch_operations_count
        type: integer
        min: 0
        required: false
        description: |
          Number of batch operations performed (creating multiple entities in parallel).
          Higher values indicate better efficiency through parallelization.

  - name: user_feedback
    brief: "User-provided feedback about the session"
    description: |
      Optional feedback provided by the user about the session quality, accuracy,
      and usefulness. Used to improve AI performance and system reliability.
    parents:
      - child_fk: session_id
        parent_array: user_feedback
    primary_key: [session_id]
    fields:
      - name: session_id
        type: string
        primaryKey: true
        required: true
        foreignKey:
          entity: session_feedback
          field: session_id
        description: |
          Reference to the parent session feedback record.
      - name: rating
        type: integer
        min: 1
        max: 5
        required: false
        description: |
          User rating on a scale of 1-5, where:
          1 = Poor (significant errors or issues)
          2 = Below average (some problems)
          3 = Average (acceptable but could improve)
          4 = Good (minor issues)
          5 = Excellent (no issues, high quality)
      - name: comments
        type: string
        required: false
        description: |
          Free-form comments from the user about the session, including what worked well,
          what didn't work, and suggestions for improvement.

  - name: ai_feedback
    brief: "AI-generated feedback about the session"
    description: |
      AI-generated feedback about the session, including processing summary, tools used,
      challenges encountered, and insights.
      
      **INSTRUCTION FOR LARGE LLMs**: Your feedback here is for HUMAN ARCHITECTS who are
      improving the system for physics paper analysis. Focus on:
      
      1. **Model Design Insights**: What did you learn about the data model that would help
         architects improve physics fact extraction? What information was hard to find? What
         guidance was unclear for ensuring correctness, completeness, minimal representation,
         and consistency?
      
      2. **Challenges Encountered**: Document specific challenges encountered when analyzing
         physics papers. What required complex reasoning? What patterns were too complex? How
         did this impact correctness, completeness, minimal representation, or consistency?
      
      3. **Suggested Model Improvements**: Provide concrete suggestions for model changes that
         would help extract physics facts correctly and completely. Be specific about what to
         add, change, or remove in entity descriptions, field descriptions, or model structure
         to ensure high-quality physics fact extraction.
      
      4. **Workflow Patterns**: Document which workflow patterns worked well and which were
         problematic when processing physics papers. How did these patterns impact the four
         key success criteria?
      
      Required for every session to enable continuous improvement and quality tracking of physics
      paper analysis.
    parents:
      - child_fk: session_id
        parent_array: ai_feedback
    primary_key: [session_id]
    fields:
      - name: session_id
        type: string
        primaryKey: true
        required: true
        foreignKey:
          entity: session_feedback
          field: session_id
        description: |
          Reference to the parent session feedback record.
      - name: session_summary
        type: string
        required: true
        description: |
          Brief summary of the session, including what physics papers were analyzed, key facts
          extracted, and outcomes. Should be 2-3 sentences describing the session's purpose
          and results, emphasizing correctness, completeness, minimal representation, and
          consistency of extracted physics facts.
      - name: entities_created_summary
        type: string
        required: false
        description: |
          Summary of physics entities created during the session, including counts by type
          (theories, papers, people, assumptions, postulates, claims, predictions) and
          key relationships established. Helps understand session scope and complexity,
          and whether all key facts from papers were captured completely.
      - name: challenges_encountered
        type: array
        item_type:
          primitive: string
        required: false
        description: |
          List of challenges or difficulties encountered during processing, documented to help
          human architects understand what makes physics paper analysis difficult.
          
          **INSTRUCTION FOR LARGE LLMs**: Document challenges encountered. For each challenge,
          explain:
          - What happened
          - Why it's problematic for physics paper analysis
          - What model change would help
          
          Examples:
          - "Validation failure for 'theory' entity missing 'year' - required_fields not visible
            at depth=1. Depth=1 is often used, so required fields are missed. For physics papers,
            missing year causes correctness and consistency issues. Solution: Add required_fields
            to depth=1 response, especially for date-critical fields."
          - "Ambiguous entity description - doesn't explicitly state required fields. Explicit
            lists are needed, not inference. For physics entities, this leads to incomplete
            fact extraction. Solution: Add 'Required fields: [list]' to description, emphasizing
            importance of dates and IDs for correctness."
          - "Inconsistent relationships - theory.papers includes paper_id but paper doesn't reference
            theory. This violates consistency principle. Solution: Add explicit guidance on
            maintaining bidirectional consistency when linking physics entities."
          - "Redundant representation - same assumption extracted as both assumption and postulate
            entities. This violates minimal representation principle. Solution: Add clearer
            distinction in entity descriptions between assumptions and postulates."
      - name: what_worked_well
        type: array
        item_type:
          primitive: string
        required: false
        description: |
          List of aspects that worked well during the session, documented to help architects
          understand what model design elements enable success.
          
          **INSTRUCTION FOR LARGE LLMs**: Document what worked well and explain what in the
          model design made it possible. Help architects replicate these patterns. For each
          strength, explain:
          - What worked
          - What in the model enabled this
          - How to replicate this pattern
          
          Examples:
          - "All physics entities created successfully on first attempt with correct required
            fields - required_fields were visible at depth=1 and entity description explicitly
            listed them. This ensured correctness and completeness. To replicate: Ensure
            required_fields always visible at default depth and add explicit lists to descriptions,
            especially for date-critical fields like year."
          - "Consistent relationships maintained - theory.papers and paper references matched
            correctly. This ensured consistency across entities. To replicate: Add explicit
            guidance on maintaining bidirectional consistency when linking physics entities."
          - "Minimal representation achieved - no duplicate entities created, each fact represented
            once in most appropriate entity. To replicate: Add guidance on checking existing entities
            before creation and selecting most appropriate entity type for each fact."
      - name: suggestions_for_improvement
        type: array
        item_type:
          primitive: string
        required: false
        description: |
          Suggestions for improving the system, model, or processing workflow for physics
          paper analysis.
          
          **INSTRUCTION FOR LARGE LLMs**: Provide specific, actionable suggestions for human
          architects. Focus on model design changes. Each suggestion should:
          - Identify a specific model/design issue
          - Explain why it's problematic for physics paper analysis
          - Propose a concrete model change
          
          Examples:
          - "Add required_fields array to get_model() depth=1 response - depth=1 is often used
            and required fields at depth=2 are missed. For physics papers, this causes incomplete
            fact extraction, especially for critical date fields."
          - "Add explicit 'Required fields: [list]' to all entity descriptions - explicit lists
            are needed, not inference from field-level flags. For physics entities, emphasize
            importance of year fields for correctness and consistency."
          - "Add consistency check guidance: 'Verify years match across related entities
            (theory.year, paper.year, person birth/death years)' - consistency issues may be missed
            when extracting physics facts."
          - "Add minimal representation guidance: 'Check for existing entities before creation
            to avoid duplicates' - redundant entities may be created, violating minimal
            representation principle."
          - "Add explicit distinction between assumption and postulate entities in descriptions -
            they may be confused, leading to incorrect categorization of physics facts."
      - name: model_insights
        type: string
        required: false
        description: |
          Insights about the data model, entity relationships, or query patterns that would
          help human architects optimize the system for physics paper analysis.
          
          **INSTRUCTION FOR LARGE LLMs**: Provide insights focused on model design improvements.
          Document:
          - What patterns in the model are unclear or require too much reasoning
          - What information is hard to find or discover
          - What structural changes would make the model more accessible
          - What guidance is missing or ambiguous
          
          Examples:
          - "Required fields are only visible at depth=2, but depth=1 is often used. Making
            required_fields visible at depth=1 would significantly improve success rate for physics
            paper analysis, especially for date-critical fields like year that are essential
            for correctness."
          - "Entity descriptions don't explicitly list required fields, requiring inference
            from field-level flags. Adding explicit lists would ensure complete physics fact
            extraction."
          - "No explicit guidance on maintaining consistency across related entities (e.g.,
            theory.year should match paper.year when they're related). Adding consistency
            check guidance would help ensure data quality."
          - "Ambiguous distinction between assumption and postulate entities - they may be
            misclassified. Adding explicit examples and criteria would improve correctness."
          - "No guidance on minimal representation - duplicate entities or redundant representations
            may be created. Adding explicit guidance on checking existing entities and selecting
            most appropriate entity type would help."

